{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.spatial import KDTree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from openpyxl import Workbook\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_matrix_to_excel(matrix, filename):\n",
    "  \"\"\"\n",
    "  Xuất ma trận numpy.ndarray sang file Excel.\n",
    "\n",
    "  Args:\n",
    "    matrix: Ma trận numpy.ndarray cần xuất.\n",
    "    filename: Tên file Excel (ví dụ: 'matrix.xlsx').\n",
    "  \"\"\"\n",
    "  wb = Workbook()\n",
    "  ws = wb.active\n",
    "\n",
    "  for row in matrix:\n",
    "    ws.append(row.tolist())  # Chuyển đổi numpy.ndarray sang list\n",
    "\n",
    "  wb.save(filename)\n",
    "def update_column(matrix, N):\n",
    "    matrix[:, N] = (matrix[:, N - 1] + matrix[:, N + 1]) / 2\n",
    "    return matrix\n",
    "def k_distance(X_std, n):\n",
    "    # Xây dựng mô hình k-Means với k=10\n",
    "    neighbors = n\n",
    "    nbrs = NearestNeighbors(n_neighbors=neighbors ).fit(X_std)\n",
    "\n",
    "    # Ma trận khoảng cách distances: (N, k)\n",
    "    distances, indices = nbrs.kneighbors(X_std)\n",
    "\n",
    "    # Lấy ra khoảng cách xa nhất từ phạm vi láng giềng của mỗi điểm và sắp xếp theo thứ tự giảm dần.\n",
    "    distance_desc = sorted(distances[:, neighbors-1], reverse=True)\n",
    "\n",
    "    # Vẽ biểu đồ khoảng cách xa nhất ở trên theo thứ tự giảm dần\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(list(range(1,len(distance_desc )+1)), distance_desc)\n",
    "    plt.ylabel('distance')\n",
    "    plt.xlabel('indice')\n",
    "    plt.title(f'Sorting Maximum Distance in {n} Nearest Neighbor of kNN')\n",
    "def keep_top_N_elements(matrix, N):\n",
    "    flat_matrix = matrix.ravel()\n",
    "    indices = np.argpartition(flat_matrix, -N)[-N:]\n",
    "    result = np.zeros_like(matrix)\n",
    "    result.flat[indices] = flat_matrix[indices]\n",
    "    return result\n",
    "def find_median_x(coords):\n",
    "    # Lấy danh sách các hoành độ từ cột đầu tiên của mảng numpy\n",
    "    x_coords = coords[:, 1]  # Cột đầu tiên là tung độ\n",
    "    \n",
    "    # Sắp xếp danh sách hoành độ\n",
    "    x_coords.sort()\n",
    "    \n",
    "    # Tìm hoành độ trung bình (median)\n",
    "    n = len(x_coords)\n",
    "    if n % 2 == 1:\n",
    "        # Nếu số điểm là lẻ, median là giá trị tại giữa\n",
    "        median_x = x_coords[n // 2]\n",
    "    else:\n",
    "        # Nếu số điểm là chẵn, median là trung bình của hai giá trị giữa\n",
    "        median_x = (x_coords[n // 2 - 1] + x_coords[n // 2]) / 2\n",
    "        \n",
    "    return median_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(P, D, eps):\n",
    "  \"\"\"\n",
    "  Tìm các điểm lân cận của điểm P trong tập dữ liệu D với bán kính eps.\n",
    "\n",
    "  Args:\n",
    "    P: Điểm cần tìm lân cận.\n",
    "    D: Tập dữ liệu.\n",
    "    eps: Bán kính lân cận.\n",
    "\n",
    "  Returns:\n",
    "    Danh sách các điểm lân cận.\n",
    "  \"\"\"\n",
    "  # Scale lại tọa độ y của D (chỉ scale cột y)\n",
    "  D_scaled = D.copy()\n",
    "  D_scaled[:, 1] = D[:, 1] / 3  \n",
    "  \n",
    "  # Scale lại tọa độ y của P (chỉ scale phần tử thứ 2)\n",
    "  P_scaled = P.copy()\n",
    "  P_scaled[1] = P[1] / 3\n",
    "\n",
    "  tree = KDTree(D_scaled[:, :2])\n",
    "  indices = tree.query_ball_point(P_scaled[:2], eps)\n",
    "\n",
    "  # Lọc kết quả bằng indexing\n",
    "  neighbors = D[indices][D[indices, 2] <= P[2]] \n",
    "  \n",
    "  # Chuyển đổi kết quả sang list\n",
    "  return neighbors.tolist() \n",
    "def tim_hang(D, X):\n",
    "  \"\"\"\n",
    "  Kiểm tra sự tồn tại của hàng trong ma trận D có giá trị bằng với mảng X.\n",
    "\n",
    "  Args:\n",
    "    D: Ma trận NumPy.\n",
    "    X: Mảng NumPy.\n",
    "\n",
    "  Returns:\n",
    "    True nếu tìm thấy hàng trong ma trận D, ngược lại trả về False.\n",
    "  \"\"\"\n",
    "  return np.any(np.all(D == X, axis=1))\n",
    "def xoa_hang(D, X):\n",
    "  \"\"\"\n",
    "  Xóa hàng trong ma trận D có giá trị bằng với mảng X (tối ưu).\n",
    "\n",
    "  Args:\n",
    "    D: Ma trận NumPy.\n",
    "    X: Mảng NumPy.\n",
    "\n",
    "  Returns:\n",
    "    Ma trận NumPy mới sau khi xóa hàng.\n",
    "  \"\"\"\n",
    "  mask = ~np.all(D == X, axis=1)\n",
    "  return D[mask]\n",
    "def get_rows_not_in_set(D, C):\n",
    "  \"\"\"\n",
    "  Lấy các hàng trong ma trận D mà không xuất hiện trong set C.\n",
    "\n",
    "  Args:\n",
    "    D: Ma trận đầu vào.\n",
    "    C: Set đầu vào.\n",
    "\n",
    "  Returns:\n",
    "    Ma trận chứa các hàng trong D nhưng không trong C.\n",
    "  \"\"\"\n",
    "  # Chuyển đổi set C thành mảng numpy\n",
    "  C_np = np.array(list(C))\n",
    "  # Tìm các hàng trong D không có trong C\n",
    "  mask = ~np.any(np.all(D[:, np.newaxis] == C_np, axis=2), axis=1)\n",
    "  return D[mask]\n",
    "def KBSCAN(D,eps,MinPts):\n",
    "    clusters = {}\n",
    "    C = 1\n",
    "    unvisited = D\n",
    "    cluster_points = set()\n",
    "\n",
    "    while(unvisited.size != 0):\n",
    "        index_max = np.where(unvisited[:,2] == np.max(unvisited[:,2]))\n",
    "        P = np.array(unvisited[index_max]).reshape(3,)\n",
    "\n",
    "        neighbors = getNeighbors(P, D, eps)\n",
    "        if tim_hang(unvisited,P):\n",
    "            unvisited = xoa_hang(unvisited,P)\n",
    "        if len(neighbors) >= MinPts: \n",
    "            clusters[C] = []\n",
    "            clusters[C].append(P)\n",
    "            cluster_points.add(tuple(P))\n",
    "            for P_prime in neighbors:\n",
    "                if tim_hang(unvisited,P_prime):\n",
    "                    unvisited = xoa_hang(unvisited,P_prime)\n",
    "                    neighbors_prime = getNeighbors(P_prime,D,eps)\n",
    "                    if len(neighbors_prime) >= MinPts:\n",
    "                        neighbors.extend(neighbors_prime)\n",
    "                if tuple(P_prime) not in cluster_points:\n",
    "                    clusters[C].append(P_prime)\n",
    "                    cluster_points.add(tuple(P_prime))\n",
    "            C += 1\n",
    "\n",
    "    clusters[-1] = []\n",
    "    clusters[-1].extend(get_rows_not_in_set(D, np.array(list(cluster_points))))\n",
    "\n",
    "    Y = np.zeros((num_adc_samples,num_chirps_in_frame))\n",
    "    max_elements = 0\n",
    "    index_max_elements = None\n",
    "    for i in clusters:\n",
    "        if len(clusters[i]) > max_elements:\n",
    "            max_elements = len(clusters[i])\n",
    "            index_max_elements = i\n",
    "\n",
    "    # Lấy tọa độ x, y của các điểm trong cluster\n",
    "    x_coords = np.array([int(row[0]) for row in clusters[index_max_elements]])\n",
    "    y_coords = np.array([int(row[1]) for row in clusters[index_max_elements]])\n",
    "    # Gán giá trị i cho các tọa độ tương ứng trong ma trận Y\n",
    "    Y[x_coords, y_coords] = 1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adc_processing(adc_data):\n",
    "    \"\"\"\n",
    "    Xử lý dữ liệu ADC đầu vào từ radar một cách tối ưu bằng vector hóa NumPy.\n",
    "    \n",
    "    Args:\n",
    "    - adc_data (np.ndarray): Dữ liệu ADC thô đầu vào.\n",
    "    - num_rx (int): Số lượng nhận.\n",
    "    - num_adc_samples (int): Số mẫu ADC trên mỗi chirp.\n",
    "    - num_chirps_in_frame (int): Số chirps trong mỗi khung.\n",
    "    - num_tx (int): Số phát.\n",
    "    - num_adc_bits (int): Số bit của ADC.\n",
    "    \n",
    "    Returns:\n",
    "    - data (np.ndarray): Dữ liệu đã xử lý, sắp xếp theo định dạng (num_frames, num_chirps_in_frame, num_adc_samples).\n",
    "    - num_frames (int): Tổng số khung dữ liệu.\n",
    "    \"\"\"\n",
    "    # Điều chỉnh giá trị ADC nếu cần\n",
    "    if num_adc_bits != 16: \n",
    "        l_max = 2**(num_adc_bits-1) -1 \n",
    "        adc_data[adc_data>l_max] -= 2**num_adc_bits \n",
    "\n",
    "    file_size = adc_data.size\n",
    "    num_chirps = file_size // (2 * num_adc_samples * num_rx)\n",
    "    file_size = num_chirps * (2 * num_adc_samples * num_rx)\n",
    "    adjusted_size = (file_size//4) * 4\n",
    "\n",
    "    # Chuyển đổi ADC dữ liệu sang phức hợp\n",
    "    lvds = np.zeros((file_size//2), dtype = complex)\n",
    "    lvds[0::2] = adc_data[0:adjusted_size:4] + 1j*adc_data[2:adjusted_size:4]\n",
    "    lvds[1::2] = adc_data[1:adjusted_size:4] + 1j*adc_data[3:adjusted_size:4]\n",
    "    lvds = lvds.reshape((num_chirps), num_adc_samples*num_rx)\n",
    "\n",
    "    # Reshape dữ liệu cho mỗi RX\n",
    "    new_adc_data = np.zeros((num_rx, num_chirps * num_adc_samples), dtype = np.complex128)\n",
    "    for row in range(num_rx):\n",
    "        for i in range(num_chirps):\n",
    "            new_adc_data[row, i*num_adc_samples:(i+1)*num_adc_samples] = lvds[i, row*num_adc_samples:(row+1)*num_adc_samples]\n",
    "\n",
    "    # Xử lý RX1, TX1\n",
    "    rx1 = np.reshape(new_adc_data[0,:],(num_chirps,Ns)) \n",
    "    rx1_tx1 = rx1[0::3]\n",
    "\n",
    "    # Reshape dữ liệu thành các khung\n",
    "    num_frames = num_chirps // (num_chirps_in_frame*num_tx)\n",
    "    data = rx1_tx1[0:num_frames*num_chirps_in_frame]\n",
    "    data = data.reshape((num_frames,num_chirps_in_frame,num_adc_samples))\n",
    "\n",
    "    return data, num_frames\n",
    "def doppler_fft_without_butter(data): \n",
    "    data_time = data\n",
    "    tmp = np.fft.fft(data_time, axis = 0)\n",
    "    doppler_fft = np.fft.fft(tmp, axis = 1)\n",
    "    return doppler_fft\n",
    "def read_binary_file(file_name, chunk_size=1024*1024):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        while chunk := f.read(chunk_size):\n",
    "            yield np.frombuffer(chunk, dtype=np.int16)\n",
    "def read_binary_file_to_array(file_name, chunk_size=1024*1024):\n",
    "    \"\"\"\n",
    "    Đọc file nhị phân lớn theo từng khối dữ liệu và hợp nhất thành mảng NumPy.\n",
    "    \n",
    "    Args:\n",
    "    - file_name (str): Tên file nhị phân cần đọc.\n",
    "    - chunk_size (int): Kích thước khối dữ liệu (bytes) sẽ đọc mỗi lần.\n",
    "    \n",
    "    Returns:\n",
    "    - np.ndarray: Một mảng NumPy chứa toàn bộ dữ liệu từ file.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for chunk in read_binary_file(file_name, chunk_size):\n",
    "        chunks.append(chunk)\n",
    "    return np.concatenate(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keep_N(i,N):\n",
    "    data_test = doppler_fft_without_butter(data[i].T)\n",
    "    doppler_magnitude = np.abs(data_test)\n",
    "    velocity_bins = np.fft.fftfreq(Nc, d=1/Nc) * velocity_res\n",
    "    # Shift zero-frequency component to center of spectrum\n",
    "    doppler_magnitude = np.fft.fftshift(doppler_magnitude, axes=1)\n",
    "    velocity_bins = np.fft.fftshift(velocity_bins)\n",
    "\n",
    "    final_data = 20 * np.log10(doppler_magnitude)\n",
    "\n",
    "    final_data = update_column(final_data,128)\n",
    "    \n",
    "    final_data_2 = np.copy(final_data)\n",
    "    final_data_2[final_data > 70] = 100\n",
    "    final_data_2[final_data <= 70] = 0\n",
    "    indices = np.column_stack(np.where(final_data_2 == 100))\n",
    "    db = DBSCAN(eps=3, min_samples=3)\n",
    "    labels = db.fit_predict(indices)\n",
    "    label_counts = Counter(labels)\n",
    "    most_frequent_label = label_counts.most_common(1)[0][0]\n",
    "    new_labels = [0 if label == most_frequent_label else 1 for label in labels]\n",
    "\n",
    "    Y = np.zeros_like(final_data)\n",
    "    for i, label in enumerate(new_labels):\n",
    "        if label != -1:  # -1 là chỉ các điểm nhiễu (outliers) trong DBSCAN\n",
    "            Y[indices[i, 0], indices[i, 1]] = label # Gán nhãn bắt đầu từ 1\n",
    "\n",
    "    final_data = final_data - 30 * Y\n",
    "    final_data = keep_top_N_elements(final_data,N)\n",
    "    # Plot the Range-Velocity Map\n",
    "    plt.figure(figsize=(30, 12))\n",
    "    im =plt.imshow(final_data, aspect='auto', cmap='jet', extent=[velocity_bins.min(), velocity_bins.max(), R_max, 0])\n",
    "    # Set the colorbar limits\n",
    "    clim = im.get_clim()\n",
    "    im.set_clim(clim[1]-25, clim[1])\n",
    "    plt.title('Range-Velocity Map')\n",
    "    plt.ylabel('Range (m)')\n",
    "    plt.xlabel('Velocity (m/s)')\n",
    "    plt.colorbar(label='Magnitude (dB)')\n",
    "    plt.show()\n",
    "def plot_keep_N_ghost(i,N):\n",
    "    data_test = doppler_fft_without_butter(data[i].T)\n",
    "    doppler_magnitude = np.abs(data_test)\n",
    "    velocity_bins = np.fft.fftfreq(Nc, d=1/Nc) * velocity_res\n",
    "    # Shift zero-frequency component to center of spectrum\n",
    "    doppler_magnitude = np.fft.fftshift(doppler_magnitude, axes=1)\n",
    "    velocity_bins = np.fft.fftshift(velocity_bins)\n",
    "\n",
    "    final_data = 20 * np.log10(doppler_magnitude)\n",
    "\n",
    "    final_data = update_column(final_data,128)\n",
    "    \n",
    "    final_data = keep_top_N_elements(final_data,N)\n",
    "    # Plot the Range-Velocity Map\n",
    "    plt.figure(figsize=(30, 12))\n",
    "    im =plt.imshow(final_data, aspect='auto', cmap='jet', extent=[velocity_bins.min(), velocity_bins.max(), R_max, 0])\n",
    "    # Set the colorbar limits\n",
    "    clim = im.get_clim()\n",
    "    im.set_clim(clim[1]-25, clim[1])\n",
    "    plt.title('Range-Velocity Map')\n",
    "    plt.ylabel('Range (m)')\n",
    "    plt.xlabel('Velocity (m/s)')\n",
    "    plt.colorbar(label='Magnitude (dB)')\n",
    "    plt.show()\n",
    "def cal_vec(i,N):\n",
    "    data_test = doppler_fft_without_butter(data[i].T)\n",
    "    doppler_magnitude = np.abs(data_test)\n",
    "    velocity_bins = np.fft.fftfreq(Nc, d=1/Nc) * velocity_res\n",
    "    # Shift zero-frequency component to center of spectrum\n",
    "    doppler_magnitude = np.fft.fftshift(doppler_magnitude, axes=1)\n",
    "    velocity_bins = np.fft.fftshift(velocity_bins)\n",
    "\n",
    "    final_data = 20 * np.log10(doppler_magnitude)\n",
    "\n",
    "    final_data = update_column(final_data,128)\n",
    "    \n",
    "    final_data_2 = np.copy(final_data)\n",
    "    final_data_2[final_data > 70] = 100\n",
    "    final_data_2[final_data <= 70] = 0\n",
    "    indices = np.column_stack(np.where(final_data_2 == 100))\n",
    "    db = DBSCAN(eps=3, min_samples=3)\n",
    "    labels = db.fit_predict(indices)\n",
    "    label_counts = Counter(labels)\n",
    "    most_frequent_label = label_counts.most_common(1)[0][0]\n",
    "    new_labels = [0 if label == most_frequent_label else 1 for label in labels]\n",
    "\n",
    "    Y = np.zeros_like(final_data)\n",
    "    for i, label in enumerate(new_labels):\n",
    "        if label != -1:  # -1 là chỉ các điểm nhiễu (outliers) trong DBSCAN\n",
    "            Y[indices[i, 0], indices[i, 1]] = label # Gán nhãn bắt đầu từ 1\n",
    "\n",
    "    final_data = final_data - 30 * Y\n",
    "    final_data = keep_top_N_elements(final_data,N)\n",
    "\n",
    "    indices_2 = np.column_stack(np.where(final_data > 1))\n",
    "    torso_vec = int(find_median_x(indices_2))\n",
    "\n",
    "    return(torso_vec)\n",
    "def cal_vec_with_ghost(i,N):\n",
    "    data_test = doppler_fft_without_butter(data[i].T)\n",
    "    doppler_magnitude = np.abs(data_test)\n",
    "    velocity_bins = np.fft.fftfreq(Nc, d=1/Nc) * velocity_res\n",
    "    # Shift zero-frequency component to center of spectrum\n",
    "    doppler_magnitude = np.fft.fftshift(doppler_magnitude, axes=1)\n",
    "    velocity_bins = np.fft.fftshift(velocity_bins)\n",
    "\n",
    "    final_data = 20 * np.log10(doppler_magnitude)\n",
    "\n",
    "    final_data = update_column(final_data,128)\n",
    "    final_data = keep_top_N_elements(final_data,N)\n",
    "\n",
    "    indices_2 = np.column_stack(np.where(final_data > 1))\n",
    "    torso_vec = int(find_median_x(indices_2))\n",
    "\n",
    "    return(torso_vec)\n",
    "def plot_vec_ghost(N):\n",
    "    vec_time_with_ghost = np.zeros(num_frames)\n",
    "    for i in range(num_frames): \n",
    "        vec_time_with_ghost[i] = cal_vec_with_ghost(i,N)\n",
    "\n",
    "    data_final_2 = (vec_time_with_ghost / num_chirps_in_frame) * 37.4 - 18.7\n",
    "    x = list(range(len(data_final_2)))\n",
    "\n",
    "    # Trục tung là giá trị của các phần tử trong mảng\n",
    "    y = data_final_2\n",
    "\n",
    "    plt.figure(figsize=(30, 12))\n",
    "    # Vẽ đồ thị\n",
    "    plt.plot(x, y, marker='o')\n",
    "\n",
    "    # Gán nhãn trục\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Vận tốc thân')\n",
    "\n",
    "    plt.title(f'Đồ thị vận tốc theo frame (chưa lọc) - Giá trị i = {N}')\n",
    "    # Hiển thị đồ thị\n",
    "\n",
    "    plt.show()\n",
    "def plot_vec(N):\n",
    "    vec_time = np.zeros(267)\n",
    "    for i in range(267): \n",
    "        vec_time[i] = cal_vec(i,N)\n",
    "\n",
    "    data_final = (vec_time / num_chirps_in_frame) * 37.4 - 18.7\n",
    "    x = list(range(len(data_final)))\n",
    "\n",
    "    # Trục tung là giá trị của các phần tử trong mảng\n",
    "    y = data_final\n",
    "\n",
    "    plt.figure(figsize=(30, 12))\n",
    "    # Vẽ đồ thị\n",
    "    plt.plot(x, y, marker='o')\n",
    "\n",
    "    # Gán nhãn trục\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Vận tốc thân')\n",
    "    plt.title(f'Đồ thị vận tốc theo frame (đã lọc) - Giá trị i = {N}')\n",
    "    # Hiển thị đồ thị\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_original(i):\n",
    "    # Plot the Range-Velocity Map\n",
    "    plt.figure(figsize=(30, 12))\n",
    "    im =plt.imshow(preprocessed_data[i], aspect='auto', cmap='jet', extent=[velocity_bins.min(), velocity_bins.max(), R_max, 0])\n",
    "    clim = im.get_clim()\n",
    "    im.set_clim(clim[1] - 70, clim[1])\n",
    "    plt.title('Range-Velocity Map')\n",
    "    plt.ylabel('Range (m)')\n",
    "    plt.xlabel('Velocity (m/s)')\n",
    "    plt.colorbar(label='Magnitude (dB)')\n",
    "    plt.show()\n",
    "def plot_bf_cluster(i):\n",
    "    final_data = np.copy(preprocessed_data[i])\n",
    "    final_data[final_data > 70] = 100\n",
    "    final_data[final_data <= 70] = 0\n",
    "\n",
    "    # Plot the Range-Velocity Map\n",
    "    plt.figure(figsize=(30, 12))\n",
    "    im =plt.imshow(final_data, aspect='auto', cmap='jet', extent=[velocity_bins.min(), velocity_bins.max(), R_max, 0])\n",
    "    clim = im.get_clim()\n",
    "    im.set_clim(clim[0], clim[1])\n",
    "    plt.title('Range-Velocity Map')\n",
    "    plt.ylabel('Range (m)')\n",
    "    plt.xlabel('Velocity (m/s)')\n",
    "    plt.colorbar(label='Magnitude (dB)')\n",
    "    plt.show()\n",
    "def plot_af_cluster(i):\n",
    "    final_data = np.copy(preprocessed_data[i])\n",
    "    final_data[final_data > 70] = 100\n",
    "    final_data[final_data <= 70] = 0\n",
    "\n",
    "    #DBSCAN\n",
    "    indices = np.column_stack(np.where(final_data == 100))\n",
    "    db = hdbscan.HDBSCAN(min_cluster_size=3, cluster_selection_epsilon=3)\n",
    "    labels = db.fit_predict(indices)\n",
    "    #Tìm lấy cụm có số phần tử nhiều nhất\n",
    "    label_counts = Counter(labels)\n",
    "    most_frequent_label = label_counts.most_common(1)[0][0]\n",
    "    new_labels = [0 if label == most_frequent_label else 1 for label in labels]\n",
    "    #Output ma trận nhãn\n",
    "    Y = np.zeros_like(final_data)\n",
    "    for i, label in enumerate(new_labels):\n",
    "            Y[indices[i, 0], indices[i, 1]] = label + 1\n",
    "\n",
    "    # Vẽ hình ảnh trực quan của ma trận Y (các cụm được gán nhãn)\n",
    "    plt.figure(figsize=(30, 12))\n",
    "    plt.imshow(Y, cmap='tab20', interpolation='nearest')\n",
    "    plt.title('DBSCAN Clustering on Matrix X')\n",
    "    plt.colorbar(label='Cluster Label')\n",
    "    plt.show()\n",
    "def plot_final(i):\n",
    "    final_data = np.copy(preprocessed_data[i])\n",
    "    final_data_2 = np.copy(final_data)\n",
    "    final_data_2[final_data > 70] = 100\n",
    "    final_data_2[final_data <= 70] = 0\n",
    "\n",
    "    #DBSCAN\n",
    "    indices = np.column_stack(np.where(final_data_2 == 100))\n",
    "    db = hdbscan.HDBSCAN(min_cluster_size=3, cluster_selection_epsilon=3)\n",
    "    labels = db.fit_predict(indices)\n",
    "    #Tìm lấy cụm có số phần tử nhiều nhất\n",
    "    label_counts = Counter(labels)\n",
    "    most_frequent_label = label_counts.most_common(1)[0][0]\n",
    "    new_labels = [1 if label == most_frequent_label else 0 for label in labels]\n",
    "    #Output ma trận nhãn\n",
    "    Y = np.zeros_like(final_data)\n",
    "    for i, label in enumerate(new_labels):\n",
    "        Y[indices[i, 0], indices[i, 1]] = label\n",
    "    #Output ma trận RD sau khi phân cụm\n",
    "    mean = np.mean(final_data)\n",
    "    final_data[Y<0.5] = mean\n",
    "\n",
    "    # Plot the Range-Velocity Map\n",
    "    plt.figure(figsize=(30, 12))\n",
    "    im =plt.imshow(final_data, aspect='auto', cmap='jet', extent=[velocity_bins.min(), velocity_bins.max(), R_max, 0])\n",
    "    # Set the colorbar limits\n",
    "    clim = im.get_clim()\n",
    "    im.set_clim(clim[1]- 40, clim[1])\n",
    "    plt.title('Range-Velocity Map')\n",
    "    plt.ylabel('Range (m)')\n",
    "    plt.xlabel('Velocity (m/s)')\n",
    "    plt.colorbar(label='Magnitude (dB)')\n",
    "    plt.show()\n",
    "def plot_KBSCAN(i):\n",
    "    final_data = np.copy(preprocessed_data[i])\n",
    "    final_data_2 = np.copy(final_data)\n",
    "    final_data_2[final_data > 70] = 100\n",
    "    final_data_2[final_data <= 70] = 0\n",
    "\n",
    "    #DBSCAN\n",
    "    indices = np.column_stack(np.where(final_data_2 == 100))\n",
    "    db = hdbscan.HDBSCAN(min_cluster_size=3, cluster_selection_epsilon=3)\n",
    "    labels = db.fit_predict(indices)\n",
    "    #Tìm lấy cụm có số phần tử nhiều nhất\n",
    "    label_counts = Counter(labels)\n",
    "    most_frequent_label = label_counts.most_common(1)[0][0]\n",
    "    new_labels = [1 if label == most_frequent_label else 0 for label in labels]\n",
    "    #Output ma trận nhãn\n",
    "    Y = np.zeros_like(final_data)\n",
    "    for i, label in enumerate(new_labels):\n",
    "        Y[indices[i, 0], indices[i, 1]] = label\n",
    "    mean = np.mean(final_data)\n",
    "    final_data[Y<0.5] = mean\n",
    "    #Prepare data for KBSCAN\n",
    "    indices_2 = np.column_stack(np.where(Y == 1))\n",
    "    out = np.copy(final_data)\n",
    "    out[Y < 0.5] = 0\n",
    "    k = (out[out>0]).reshape(-1,1)\n",
    "    D = np.concatenate((indices_2,k),axis=1)\n",
    "    #KBSCAN\n",
    "    Y = KBSCAN(D,2,3)\n",
    "\n",
    "    # Vẽ hình ảnh trực quan của phân cụm bằng KBSCAN\n",
    "    plt.figure(figsize=(30, 12))\n",
    "    plt.imshow(Y, cmap='tab20', interpolation='nearest')\n",
    "    plt.title('DBSCAN Clustering on Matrix X')\n",
    "    plt.colorbar(label='Cluster Label')\n",
    "    plt.show()\n",
    "def plot_final_2(i):\n",
    "    final_data = np.copy(preprocessed_data[i])\n",
    "\n",
    "    #DBSCAN\n",
    "    final_data_2 = np.copy(final_data)\n",
    "    final_data_2[final_data > 70] = 100\n",
    "    final_data_2[final_data <= 70] = 0\n",
    "    indices = np.column_stack(np.where(final_data_2 == 100))\n",
    "    db = hdbscan.HDBSCAN(min_cluster_size=3, cluster_selection_epsilon=3)\n",
    "    #Tìm lấy cụm có số phần tử nhiều nhất\n",
    "    labels = db.fit_predict(indices)\n",
    "    label_counts = Counter(labels)\n",
    "    most_frequent_label = label_counts.most_common(1)[0][0]\n",
    "    new_labels = [1 if label == most_frequent_label else 0 for label in labels]\n",
    "    #Output ma trận nhãn\n",
    "    Y = np.zeros_like(final_data)\n",
    "    for i, label in enumerate(new_labels):\n",
    "        Y[indices[i, 0], indices[i, 1]] = label\n",
    "\n",
    "    #Prepare data for KBSCAN\n",
    "    indices_2 = np.column_stack(np.where(Y == 1))\n",
    "    out = np.copy(final_data)\n",
    "    out[Y < 0.5] = 0\n",
    "    k = (out[out>0]).reshape(-1,1)\n",
    "    D = np.concatenate((indices_2,k),axis=1)\n",
    "    #KBSCAN\n",
    "    Y = KBSCAN(D,2,3)\n",
    "\n",
    "    #Output ma trận RD sau khi phân cụm\n",
    "    mean = np.mean(final_data)\n",
    "    final_data[Y<0.5] = mean\n",
    "    \n",
    "    # Plot the Range-Velocity Map\n",
    "    plt.figure(figsize=(30, 12))\n",
    "    im =plt.imshow(final_data, aspect='auto', cmap='jet', extent=[velocity_bins.min(), velocity_bins.max(), R_max, 0])\n",
    "    # Set the colorbar limits\n",
    "    clim = im.get_clim()\n",
    "    im.set_clim(clim[1]- 40, clim[1])\n",
    "    plt.title('Range-Velocity Map')\n",
    "    plt.ylabel('Range (m)')\n",
    "    plt.xlabel('Velocity (m/s)')\n",
    "    plt.colorbar(label='Magnitude (dB)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04631058968817536\n",
      "11.11111111111111\n",
      "0.2926668350284785\n",
      "18.730677441822625\n"
     ]
    }
   ],
   "source": [
    "num_adc_bits = 16\n",
    "num_adc_samples = 128\n",
    "num_rx = 4\n",
    "num_tx = 3\n",
    "num_lanes = 2 \n",
    "is_real = 0\n",
    "num_chirps_in_frame = 128\n",
    "\n",
    "f0 = 60      # min frequency\n",
    "B = 3239     # sweep bandwidth\n",
    "S = 54       # sweep slope\n",
    "fs = 4000    # sampling freq\n",
    "Nc = 128     # num chirps in 1 frame #128 \n",
    "Ns = 128     # num samples of 1 chirp \n",
    "c0 = 3e+8\n",
    "idle_time = 5e-6\n",
    "\n",
    "fc = f0+B/2000   \n",
    "lamda = c0/(fc*1e+9)\n",
    "Tc= idle_time + (B/S)*(1e-6)\n",
    "\n",
    "R_res = c0 / (2e+6*B)       \n",
    "R_max = fs*c0 / (2e+9*S)\n",
    "velocity_res = lamda/(2*num_chirps_in_frame*Tc)\n",
    "v_max = lamda/(4*Tc)\n",
    "\n",
    "print(R_res)\n",
    "print(R_max)\n",
    "print(velocity_res)\n",
    "print(v_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Khanh_ngang_2_ban.bin\"\n",
    "chunk_size = 1024 * 1024  # Đọc từng khối 1 MB\n",
    "adc_data = read_binary_file_to_array(file_name, chunk_size)\n",
    "data, num_frames = adc_processing(adc_data)\n",
    "\n",
    "preprocessed_data = np.zeros((num_frames,Ns,num_chirps_in_frame), dtype=float)\n",
    "for i in range(num_frames):\n",
    "    data_test_test2 = doppler_fft_without_butter(data[i].T)\n",
    "    doppler_magnitude = np.abs(data_test_test2)\n",
    "    doppler_magnitude = np.fft.fftshift(doppler_magnitude, axes=1)\n",
    "    output = 20 * np.log10(doppler_magnitude)\n",
    "    output = update_column(output,int(num_chirps_in_frame/2))\n",
    "    preprocessed_data[i] = output\n",
    "\n",
    "velocity_bins = np.fft.fftfreq(num_chirps_in_frame, d=1/num_chirps_in_frame) * velocity_res\n",
    "velocity_bins = np.fft.fftshift(velocity_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plot_original(i)\n",
    "    plot_bf_cluster(i)\n",
    "    plot_af_cluster(i)\n",
    "    plot_final(i)\n",
    "    plot_KBSCAN(i)\n",
    "    plot_final_2(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_doppler_fft(ifft_data):\n",
    "    # Thực hiện inverse FFT trên trục 1 trước\n",
    "    tmp = np.fft.ifft(ifft_data, axis=1)\n",
    "    # Sau đó thực hiện inverse FFT trên trục 0\n",
    "    data_time = np.fft.ifft(tmp, axis=0)\n",
    "    return data_time\n",
    "\n",
    "def process_data_per_frame(preprocessed_data):\n",
    "    final_data = np.copy(preprocessed_data)\n",
    "\n",
    "    #DBSCAN\n",
    "    final_data_2 = np.copy(final_data)\n",
    "    final_data_2[final_data > 70] = 100\n",
    "    final_data_2[final_data <= 70] = 0\n",
    "    indices = np.column_stack(np.where(final_data_2 == 100))\n",
    "    db = hdbscan.HDBSCAN(min_cluster_size=3, cluster_selection_epsilon=3)\n",
    "    #Tìm lấy cụm có số phần tử nhiều nhất\n",
    "    labels = db.fit_predict(indices)\n",
    "    label_counts = Counter(labels)\n",
    "    most_frequent_label = label_counts.most_common(1)[0][0]\n",
    "    new_labels = [1 if label == most_frequent_label else 0 for label in labels]\n",
    "    #Output ma trận nhãn\n",
    "    Y = np.zeros_like(final_data)\n",
    "    for i, label in enumerate(new_labels):\n",
    "        Y[indices[i, 0], indices[i, 1]] = label\n",
    "\n",
    "    #Prepare data for KBSCAN\n",
    "    indices_2 = np.column_stack(np.where(Y == 1))\n",
    "    out = np.copy(final_data)\n",
    "    out[Y < 0.5] = 0\n",
    "    k = (out[out>0]).reshape(-1,1)\n",
    "    D = np.concatenate((indices_2,k),axis=1)\n",
    "    #KBSCAN\n",
    "    Y = KBSCAN(D,2,3)\n",
    "\n",
    "    #Output ma trận RD sau khi phân cụm\n",
    "    mean = np.mean(final_data)\n",
    "    final_data[Y<0.5] = mean\n",
    "\n",
    "    return final_data\n",
    "\n",
    "def process_data_all(preprocessed_data):\n",
    "    final_data = []\n",
    "    for i in range(num_frames):\n",
    "        data = process_data_per_frame(preprocessed_data[i])\n",
    "        data = 10 ** (data / 20)   \n",
    "        data = inverse_doppler_fft(data).T\n",
    "        final_data.append(data)\n",
    "\n",
    "    final_data = np.array(final_data)\n",
    "    return final_data.transpose(2, 0, 1).reshape(128, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
