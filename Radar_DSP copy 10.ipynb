{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04631058968817536\n",
      "11.11111111111111\n",
      "0.14633341751423926\n",
      "18.730677441822625\n"
     ]
    }
   ],
   "source": [
    "num_adc_bits = 16\n",
    "num_adc_samples = 128\n",
    "num_rx = 4\n",
    "num_tx = 3\n",
    "num_lanes = 2 \n",
    "is_real = 0\n",
    "num_chirps_in_frame = 256\n",
    "f0 = 60      # min frequency\n",
    "B = 3239     # sweep bandwidth\n",
    "S = 54       # sweep slope\n",
    "fs = 4000    # sampling freq\n",
    "Nc = 256     # num chirps in 1 frame\n",
    "Ns = 128     # num samples of 1 chirp \n",
    "c0 = 3e+8\n",
    "idle_time = 5e-6\n",
    "\n",
    "fc = f0+B/2000   \n",
    "lamda = c0/(fc*1e+9)\n",
    "Tc= idle_time + (B/S)*(1e-6)\n",
    "\n",
    "R_res = c0 / (2e+6*B)       \n",
    "R_max = fs*c0 / (2e+9*S)\n",
    "velocity_res = lamda/(2*Nc*Tc)\n",
    "v_max = lamda/(4*Tc)\n",
    "\n",
    "print(R_res)\n",
    "print(R_max)\n",
    "print(velocity_res)\n",
    "print(v_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adc_processing(adc_data):\n",
    "    if num_adc_bits != 16: \n",
    "        l_max = 2**(num_adc_bits-1) -1 \n",
    "        adc_data[adc_data>l_max] -= 2**num_adc_bits \n",
    "\n",
    "    file_size = adc_data.size\n",
    "    num_chirps = file_size // (2 * num_adc_samples * num_rx)\n",
    "    file_size = num_chirps * (2 * num_adc_samples * num_rx)\n",
    "    adjusted_size = (file_size//4) * 4\n",
    "\n",
    "    lvds = np.zeros((file_size//2), dtype = complex)\n",
    "    lvds[0::2] = adc_data[0:adjusted_size:4] + 1j*adc_data[2:adjusted_size:4]\n",
    "    lvds[1::2] = adc_data[1:adjusted_size:4] + 1j*adc_data[3:adjusted_size:4]\n",
    "    lvds = lvds.reshape((num_chirps), num_adc_samples*num_rx)\n",
    "\n",
    "    new_adc_data = np.zeros((num_rx, num_chirps * num_adc_samples), dtype = np.complex128)\n",
    "    for row in range(num_rx):\n",
    "        for i in range(num_chirps):\n",
    "            new_adc_data[row, i*num_adc_samples:(i+1)*num_adc_samples] = lvds[i, row*num_adc_samples:(row+1)*num_adc_samples]\n",
    "    \n",
    "    rx1 = np.reshape(new_adc_data[0,:],(num_chirps,128))\n",
    "    rx2 = np.reshape(new_adc_data[1,:],(num_chirps,128)) \n",
    "    rx3 = np.reshape(new_adc_data[2,:],(num_chirps,128))\n",
    "    rx4 = np.reshape(new_adc_data[3,:],(num_chirps,128))\n",
    "\n",
    "    rx1_tx1 = rx1[0::3]\n",
    "    rx1_tx2 = rx1[1::3]\n",
    "    rx1_tx3 = rx1[2::3]\n",
    "\n",
    "    num_frames = num_chirps // (num_chirps_in_frame*num_tx)\n",
    "    data_rx1_tx1 = rx1_tx1[0:num_frames*num_chirps_in_frame]\n",
    "    data_rx1_tx1 = data_rx1_tx1.reshape((num_frames,num_chirps_in_frame,num_adc_samples))\n",
    "\n",
    "    data_rx1_tx2 = rx1_tx2[0:num_frames*num_chirps_in_frame]\n",
    "    data_rx1_tx2 = data_rx1_tx2.reshape((num_frames,num_chirps_in_frame,num_adc_samples))\n",
    "\n",
    "    data_rx1_tx3 = rx1_tx3[0:num_frames*num_chirps_in_frame]\n",
    "    data_rx1_tx3 = data_rx1_tx3.reshape((num_frames,num_chirps_in_frame,num_adc_samples))\n",
    "\n",
    "    rx2_tx1 = rx2[0::3]\n",
    "    rx2_tx2 = rx2[1::3]\n",
    "    rx2_tx3 = rx2[2::3]\n",
    "\n",
    "    data_rx2_tx1 = rx2_tx1[0:num_frames*num_chirps_in_frame]\n",
    "    data_rx2_tx1 = data_rx2_tx1.reshape((num_frames,num_chirps_in_frame,num_adc_samples))\n",
    "    \n",
    "    data_rx2_tx2 = rx2_tx2[0:num_frames*num_chirps_in_frame]\n",
    "    data_rx2_tx2 = data_rx2_tx2.reshape((num_frames,num_chirps_in_frame,num_adc_samples))\n",
    "\n",
    "    data_rx2_tx3 = rx2_tx3[0:num_frames*num_chirps_in_frame]\n",
    "    data_rx2_tx3 = data_rx2_tx3.reshape((num_frames,num_chirps_in_frame,num_adc_samples))\n",
    "\n",
    "    rx3_tx1 = rx3[0::3]\n",
    "    rx3_tx2 = rx3[1::3]\n",
    "    rx3_tx3 = rx3[2::3]\n",
    "\n",
    "    data_rx3_tx1 = rx3_tx1[0:num_frames*num_chirps_in_frame]\n",
    "    data_rx3_tx1 = data_rx3_tx1.reshape((num_frames,num_chirps_in_frame,num_adc_samples))\n",
    "    \n",
    "    data_rx3_tx2 = rx3_tx2[0:num_frames*num_chirps_in_frame]\n",
    "    data_rx3_tx2 = data_rx3_tx2.reshape((num_frames,num_chirps_in_frame,num_adc_samples))\n",
    "\n",
    "    data_rx3_tx3 = rx3_tx3[0:num_frames*num_chirps_in_frame]\n",
    "    data_rx3_tx3 = data_rx3_tx3.reshape((num_frames,num_chirps_in_frame,num_adc_samples))\n",
    "\n",
    "    rx4_tx1 = rx4[0::3]\n",
    "    rx4_tx2 = rx4[1::3]\n",
    "    rx4_tx3 = rx4[2::3]\n",
    "\n",
    "    data_rx4_tx1 = rx4_tx1[0:num_frames*num_chirps_in_frame]\n",
    "    data_rx4_tx1 = data_rx4_tx1.reshape((num_frames,num_chirps_in_frame,num_adc_samples))\n",
    "    \n",
    "    data_rx4_tx2 = rx4_tx2[0:num_frames*num_chirps_in_frame]\n",
    "    data_rx4_tx2 = data_rx4_tx2.reshape((num_frames,num_chirps_in_frame,num_adc_samples))\n",
    "    \n",
    "    data_rx4_tx3 = rx4_tx3[0:num_frames*num_chirps_in_frame]\n",
    "    data_rx4_tx3 = data_rx4_tx3.reshape((num_frames,num_chirps_in_frame,num_adc_samples))\n",
    "\n",
    "\n",
    "    print(num_frames)\n",
    "    return data_rx1_tx1 , data_rx1_tx2, data_rx1_tx3, data_rx2_tx1, data_rx2_tx2, data_rx2_tx3, data_rx3_tx1, data_rx3_tx2, data_rx3_tx3, data_rx4_tx1, data_rx4_tx2, data_rx4_tx3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n"
     ]
    }
   ],
   "source": [
    "file_name = \"Nguyen_di_ngang_3m_2_ban.bin\"\n",
    "with open(file_name,'rb') as fid:\n",
    "    adc_data = np.fromfile(fid, dtype = np.int16)\n",
    "\n",
    "data_rx1_tx1 , data_rx1_tx2, data_rx1_tx3, data_rx2_tx1, data_rx2_tx2, data_rx2_tx3, data_rx3_tx1, data_rx3_tx2, data_rx3_tx3, data_rx4_tx1, data_rx4_tx2, data_rx4_tx3 = adc_processing(adc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doppler_fft_without_butter(data): \n",
    "    data_time = data\n",
    "    tmp = np.fft.fft(data_time, axis = 0)\n",
    "    doppler_fft = np.fft.fft(tmp, axis = 1)\n",
    "    return doppler_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doppler_fft(data): \n",
    "    data_time = data\n",
    "    tmp = np.fft.fft(data_time, axis = 0)\n",
    "\n",
    "    b, a = signal.butter(4, 0.0075, 'high')\n",
    "    data_range = signal.lfilter(b, a, tmp, axis = 1)\n",
    "\n",
    "    doppler_fft = np.fft.fft(data_range, axis = 1)\n",
    "    return doppler_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_column(matrix, N):\n",
    "    # Xử lý việc cập nhật cột thứ N\n",
    "    M = len(matrix)  # kích thước của ma trận MxM\n",
    "    \n",
    "    # Duyệt qua từng phần tử của cột N (trừ các phần tử đầu và cuối vì không có đủ phần tử bên trái hoặc phải)\n",
    "    for i in range(M):\n",
    "        # Tính giá trị trung bình cộng của phần tử bên trái và bên phải\n",
    "        matrix[i][N] = (matrix[i][N - 1] + matrix[i][N + 1]) / 2\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(P, D, eps):\n",
    "  \"\"\"\n",
    "  Tìm các điểm lân cận của điểm P trong tập dữ liệu D với bán kính eps.\n",
    "\n",
    "  Args:\n",
    "    P: Điểm cần tìm lân cận.\n",
    "    D: Tập dữ liệu.\n",
    "    eps: Bán kính lân cận.\n",
    "\n",
    "  Returns:\n",
    "    Danh sách các điểm lân cận.\n",
    "  \"\"\"\n",
    "  # Scale lại tọa độ y của D (chỉ scale cột y)\n",
    "  D_scaled = D.copy()\n",
    "  D_scaled[:, 1] = D[:, 1] / 3  \n",
    "  \n",
    "  # Scale lại tọa độ y của P (chỉ scale phần tử thứ 2)\n",
    "  P_scaled = P.copy()\n",
    "  P_scaled[1] = P[1] / 3\n",
    "\n",
    "  tree = KDTree(D_scaled[:, :2])\n",
    "  indices = tree.query_ball_point(P_scaled[:2], eps)\n",
    "\n",
    "  # Lọc kết quả bằng indexing\n",
    "  neighbors = D[indices][D[indices, 2] <= P[2]] \n",
    "  \n",
    "  # Chuyển đổi kết quả sang list\n",
    "  return neighbors.tolist() \n",
    "\n",
    "def tim_hang(D, X):\n",
    "  \"\"\"\n",
    "  Kiểm tra sự tồn tại của hàng trong ma trận D có giá trị bằng với mảng X.\n",
    "\n",
    "  Args:\n",
    "    D: Ma trận NumPy.\n",
    "    X: Mảng NumPy.\n",
    "\n",
    "  Returns:\n",
    "    True nếu tìm thấy hàng trong ma trận D, ngược lại trả về False.\n",
    "  \"\"\"\n",
    "  return np.any(np.all(D == X, axis=1))\n",
    "\n",
    "def xoa_hang(D, X):\n",
    "  \"\"\"\n",
    "  Xóa hàng trong ma trận D có giá trị bằng với mảng X (tối ưu).\n",
    "\n",
    "  Args:\n",
    "    D: Ma trận NumPy.\n",
    "    X: Mảng NumPy.\n",
    "\n",
    "  Returns:\n",
    "    Ma trận NumPy mới sau khi xóa hàng.\n",
    "  \"\"\"\n",
    "  mask = ~np.all(D == X, axis=1)\n",
    "  return D[mask]\n",
    "\n",
    "def get_rows_not_in_set(D, C):\n",
    "  \"\"\"\n",
    "  Lấy các hàng trong ma trận D mà không xuất hiện trong set C.\n",
    "\n",
    "  Args:\n",
    "    D: Ma trận đầu vào.\n",
    "    C: Set đầu vào.\n",
    "\n",
    "  Returns:\n",
    "    Ma trận chứa các hàng trong D nhưng không trong C.\n",
    "  \"\"\"\n",
    "  # Chuyển đổi set C thành mảng numpy\n",
    "  C_np = np.array(list(C))\n",
    "  # Tìm các hàng trong D không có trong C\n",
    "  mask = ~np.any(np.all(D[:, np.newaxis] == C_np, axis=2), axis=1)\n",
    "  return D[mask]\n",
    "\n",
    "def KBSCAN(D,eps,MinPts):\n",
    "    clusters = {}\n",
    "    C = 1\n",
    "    unvisited = D\n",
    "    cluster_points = set()\n",
    "\n",
    "    while(unvisited.size != 0):\n",
    "        index_max = np.where(unvisited[:,2] == np.max(unvisited[:,2]))\n",
    "        P = np.array(unvisited[index_max]).reshape(3,)\n",
    "\n",
    "        neighbors = getNeighbors(P, D, eps)\n",
    "        if tim_hang(unvisited,P):\n",
    "            unvisited = xoa_hang(unvisited,P)\n",
    "        if len(neighbors) >= MinPts: \n",
    "            clusters[C] = []\n",
    "            clusters[C].append(P)\n",
    "            cluster_points.add(tuple(P))\n",
    "            for P_prime in neighbors:\n",
    "                if tim_hang(unvisited,P_prime):\n",
    "                    unvisited = xoa_hang(unvisited,P_prime)\n",
    "                    neighbors_prime = getNeighbors(P_prime,D,eps)\n",
    "                    if len(neighbors_prime) >= MinPts:\n",
    "                        neighbors.extend(neighbors_prime)\n",
    "                if tuple(P_prime) not in cluster_points:\n",
    "                    clusters[C].append(P_prime)\n",
    "                    cluster_points.add(tuple(P_prime))\n",
    "            C += 1\n",
    "\n",
    "    clusters[-1] = []\n",
    "    clusters[-1].extend(get_rows_not_in_set(D, np.array(list(cluster_points))))\n",
    "\n",
    "    Y = np.zeros((128,256))\n",
    "    max_elements = 0\n",
    "    index_max_elements = None\n",
    "    for i in clusters:\n",
    "        if len(clusters[i]) > max_elements:\n",
    "            max_elements = len(clusters[i])\n",
    "            index_max_elements = i\n",
    "\n",
    "    # Lấy tọa độ x, y của các điểm trong cluster\n",
    "    x_coords = np.array([int(row[0]) for row in clusters[index_max_elements]])\n",
    "    y_coords = np.array([int(row[1]) for row in clusters[index_max_elements]])\n",
    "    # Gán giá trị i cho các tọa độ tương ứng trong ma trận Y\n",
    "    Y[x_coords, y_coords] = 1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KBSCAN_plot(data):\n",
    "    #Data preprocessing\n",
    "    data_test = doppler_fft_without_butter(data.T)\n",
    "    doppler_magnitude = np.abs(data_test)\n",
    "    velocity_bins = np.fft.fftfreq(Nc, d=1/Nc) * velocity_res\n",
    "    doppler_magnitude = np.fft.fftshift(doppler_magnitude, axes=1)\n",
    "    velocity_bins = np.fft.fftshift(velocity_bins)\n",
    "\n",
    "    output_test = 20 * np.log10(doppler_magnitude)\n",
    "    output_test = update_column(output_test,128)\n",
    "\n",
    "    output_test_2 = np.copy(output_test)\n",
    "    output_test_2[output_test > 70] = 100\n",
    "    output_test_2[output_test <= 70] = 0\n",
    "\n",
    "    indices = np.column_stack(np.where(output_test_2 == 100))\n",
    "\n",
    "    #DBSCAN\n",
    "    db = DBSCAN(eps=3, min_samples=3)\n",
    "    labels = db.fit_predict(indices)\n",
    "    label_counts = Counter(labels)\n",
    "    most_frequent_label = label_counts.most_common(1)[0][0]\n",
    "    new_labels = [1 if label == most_frequent_label else 0 for label in labels]\n",
    "    Y = np.zeros_like(output_test)\n",
    "    for i, label in enumerate(new_labels):\n",
    "        if label != -1:  # -1 là chỉ các điểm nhiễu (outliers) trong DBSCAN\n",
    "            Y[indices[i, 0], indices[i, 1]] = label  # Gán nhãn bắt đầu từ 1\n",
    "    indices_2 = np.column_stack(np.where(Y == 1))\n",
    "    out = np.copy(output_test)\n",
    "    out[Y < 0.5] = 0\n",
    "    k = (out[out>0]).reshape(-1,1)\n",
    "\n",
    "    #KBSCAN\n",
    "    D = np.concatenate((indices_2,k),axis=1)\n",
    "    Y = KBSCAN(D,2,3)\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n"
     ]
    }
   ],
   "source": [
    "# Hàm plot_final nhận từng data và trả về output_test\n",
    "def plot_final_full(data):\n",
    "    data_test = doppler_fft_without_butter(data.T)\n",
    "    doppler_magnitude = np.abs(data_test)\n",
    "    velocity_bins = np.fft.fftfreq(Nc, d=1 / Nc) * velocity_res\n",
    "\n",
    "    # Shift zero-frequency component to center of spectrum\n",
    "    doppler_magnitude = np.fft.fftshift(doppler_magnitude, axes=1)\n",
    "    velocity_bins = np.fft.fftshift(velocity_bins)\n",
    "\n",
    "    output_test = 20 * np.log10(doppler_magnitude)\n",
    "    output_test = update_column(output_test, 128)\n",
    "\n",
    "    output_test_2 = np.copy(output_test)\n",
    "    output_test_2[output_test > 70] = 100\n",
    "    output_test_2[output_test <= 70] = 0\n",
    "\n",
    "    indices = np.column_stack(np.where(output_test_2 == 100))\n",
    "    db = DBSCAN(eps=3, min_samples=3)\n",
    "    labels = db.fit_predict(indices)\n",
    "\n",
    "    label_counts = Counter(labels)\n",
    "\n",
    "    # Tìm cụm có số phần tử nhiều nhất\n",
    "    most_frequent_label = label_counts.most_common(1)[0][0]\n",
    "\n",
    "    # Gán nhãn mới\n",
    "    new_labels = [1 if label == most_frequent_label else 0 for label in labels]\n",
    "\n",
    "    # Gán nhãn cho ma trận Y (cùng kích thước với ma trận X)\n",
    "    Y = np.zeros_like(output_test)\n",
    "    for i, label in enumerate(new_labels):\n",
    "        if label != -1:  # -1 là chỉ các điểm nhiễu (outliers) trong DBSCAN\n",
    "            Y[indices[i, 0], indices[i, 1]] = label  # Gán nhãn bắt đầu từ 1\n",
    "\n",
    "    mean = np.mean(output_test)\n",
    "    output_test[Y < 0.5] = mean\n",
    "\n",
    "    nhan = KBSCAN_plot(data)\n",
    "    output_test = output_test * nhan\n",
    "\n",
    "    return output_test\n",
    "\n",
    "# Danh sách data đầu vào từ adc_processing\n",
    "(\n",
    "    data_rx1_tx1, data_rx1_tx2, data_rx1_tx3,\n",
    "    data_rx2_tx1, data_rx2_tx2, data_rx2_tx3,\n",
    "    data_rx3_tx1, data_rx3_tx2, data_rx3_tx3,\n",
    "    data_rx4_tx1, data_rx4_tx2, data_rx4_tx3\n",
    ") = adc_processing(adc_data)\n",
    "\n",
    "f = 1 # Chỉ số frame cần xử lý\n",
    "# Tạo danh sách các data cần xử lý\n",
    "data_list = [\n",
    "    data_rx1_tx1[f], data_rx1_tx2[f], data_rx1_tx3[f],\n",
    "    data_rx2_tx1[f], data_rx2_tx2[f], data_rx2_tx3[f],\n",
    "    data_rx3_tx1[f], data_rx3_tx2[f], data_rx3_tx3[f],\n",
    "    data_rx4_tx1[f], data_rx4_tx2[f], data_rx4_tx3[f]\n",
    "]\n",
    "\n",
    "data_list_full = [\n",
    "    data_rx1_tx1, data_rx1_tx2, data_rx1_tx3,\n",
    "    data_rx2_tx1, data_rx2_tx2, data_rx2_tx3,\n",
    "    data_rx3_tx1, data_rx3_tx2, data_rx3_tx3,\n",
    "    data_rx4_tx1, data_rx4_tx2, data_rx4_tx3\n",
    "]\n",
    "\n",
    "# Xử lý tất cả các data và lưu kết quả\n",
    "output_tests = [plot_final_full(data) for data in data_list] # data_list_full\n",
    "\n",
    "# output_tests chứa kết quả output_test cho từng data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_doppler_fft(ifft_data):\n",
    "    # Thực hiện inverse FFT trên trục 1 trước\n",
    "    tmp = np.fft.ifft(ifft_data, axis=1)\n",
    "    # Sau đó thực hiện inverse FFT trên trục 0\n",
    "    data_time = np.fft.ifft(tmp, axis=0)\n",
    "    return data_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa dải frame cần xử lý\n",
    "f_start = 0  # Bắt đầu từ frame 0\n",
    "f_end = 288  # Kết thúc tại frame 287 (tổng cộng 288 frames)\n",
    "\n",
    "# Tạo danh sách để lưu kết quả\n",
    "output_tests_rx1_tx1 = []\n",
    "\n",
    "# Duyệt qua từng frame và xử lý\n",
    "for f in range(f_start, f_end):\n",
    "    # Chọn dữ liệu frame f của data_rx1_tx1\n",
    "    data = data_rx1_tx1[f]\n",
    "    \n",
    "    # Áp dụng hàm plot_final_full cho dữ liệu frame hiện tại\n",
    "    output_test = plot_final_full(data)\n",
    "    output_test = 10 ** (output_test / 20)   \n",
    "    output_test = inverse_doppler_fft(output_test).T\n",
    "    \n",
    "    # Lưu kết quả của frame vào danh sách\n",
    "    output_tests_rx1_tx1.append(output_test)\n",
    "\n",
    "# Sau khi hoàn thành, output_tests_rx1_tx1 chứa kết quả của 288 frame.\n",
    "\n",
    "# Tạo danh sách để lưu kết quả\n",
    "output_tests_rx1_tx2 = []\n",
    "\n",
    "# Duyệt qua từng frame và xử lý\n",
    "for f in range(f_start, f_end):\n",
    "    # Chọn dữ liệu frame f của data_rx1_tx1\n",
    "    data = data_rx1_tx2[f]\n",
    "    \n",
    "    # Áp dụng hàm plot_final_full cho dữ liệu frame hiện tại\n",
    "    output_test = plot_final_full(data)\n",
    "    output_test = 10 ** (output_test / 20)   \n",
    "\n",
    "    output_test = inverse_doppler_fft(output_test).T\n",
    "    \n",
    "    # Lưu kết quả của frame vào danh sách\n",
    "    output_tests_rx1_tx2.append(output_test)\n",
    "\n",
    "\n",
    "# Tạo danh sách để lưu kết quả\n",
    "output_tests_rx1_tx3 = []\n",
    "\n",
    "# Duyệt qua từng frame và xử lý\n",
    "for f in range(f_start, f_end):\n",
    "    # Chọn dữ liệu frame f của data_rx1_tx1\n",
    "    data = data_rx1_tx3[f]\n",
    "    \n",
    "    # Áp dụng hàm plot_final_full cho dữ liệu frame hiện tại\n",
    "    output_test = plot_final_full(data)\n",
    "    output_test = 10 ** (output_test / 20)   \n",
    "    output_test = inverse_doppler_fft(output_test).T\n",
    "    # Lưu kết quả của frame vào danh sách\n",
    "    output_tests_rx1_tx3.append(output_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### vẽ\n",
    "\n",
    "#velocity_bins = np.fft.fftfreq(Nc, d=1/Nc) * velocity_res\n",
    "# velocity_bins = np.fft.fftshift(velocity_bins)\n",
    "# # Plot the Range-Velocity Map\n",
    "# plt.figure(figsize=(30, 12))\n",
    "# im =plt.imshow(output_tests[0], aspect='auto', cmap='jet', extent=[velocity_bins.min(), velocity_bins.max(), R_max, 0])\n",
    "# # Set the colorbar limits\n",
    "# clim = im.get_clim()\n",
    "# im.set_clim(clim[1]- 40, clim[1])\n",
    "# plt.title('Range-Velocity Map')\n",
    "# plt.ylabel('Range (m)')\n",
    "# plt.xlabel('Velocity (m/s)')\n",
    "# plt.colorbar(label='Magnitude (dB)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tests_rx1_tx1 = np.array(output_tests_rx1_tx1)\n",
    "output_tests_rx1_tx2 = np.array(output_tests_rx1_tx2)\n",
    "output_tests_rx1_tx3 = np.array(output_tests_rx1_tx3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 256, 128)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tests_rx1_tx1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_output_tests(output_tests):\n",
    "    return output_tests.transpose(2, 0, 1).reshape(128, -1)\n",
    "\n",
    "# Chuyển đổi tất cả output_tests\n",
    "rD1_1 = reshape_output_tests(output_tests_rx1_tx1)\n",
    "rD1_2 = reshape_output_tests(output_tests_rx1_tx2)\n",
    "rD1_3 = reshape_output_tests(output_tests_rx1_tx3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 73728)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rD1_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước mảng kết quả: (128, 221184)\n"
     ]
    }
   ],
   "source": [
    "# Số cột trong mỗi mảng\n",
    "num_columns = rD1_1.shape[1]\n",
    "\n",
    "# Tạo danh sách để lưu các cột đã hoán đổi\n",
    "reordered_columns = []\n",
    "\n",
    "# Duyệt qua từng cột\n",
    "for i in range(num_columns):\n",
    "    reordered_columns.append(rD1_1[:, i])  # Cột thứ i của rD1_1\n",
    "    reordered_columns.append(rD1_2[:, i])  # Cột thứ i của rD1_2\n",
    "    reordered_columns.append(rD1_3[:, i])  # Cột thứ i của rD1_3\n",
    "\n",
    "# Chuyển danh sách thành mảng numpy\n",
    "result = np.column_stack(reordered_columns)\n",
    "\n",
    "# Kiểm tra kích thước kết quả\n",
    "print(\"Kích thước mảng kết quả:\", result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_time = rD1_1\n",
    "tmp = np.fft.fft(Data_time, axis=0)\n",
    "b, a = signal.butter(4, 0.0075, 'high')   \n",
    "# Perform Range\n",
    "Data_range_MTI = signal.lfilter(b,a,tmp, axis=1)\n",
    "rD1 = Data_range_MTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mD_max = 865 # xem code đức check \n",
    "n_chirps = 221184 # ngắn hơn do bị cắt lúc đầu\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 12))\n",
    "# Plot the spectrogram\n",
    "\n",
    "#epsilon = 1e-10  # Giá trị nhỏ để tránh log(0)\n",
    "im = ax.imshow(20 * np.log10(np.abs(rD1)), cmap='jet', aspect='auto')\n",
    "# Set the axis labels and title\n",
    "ax.set_xlabel('No. of Sweeps')\n",
    "ax.set_ylabel('Range')\n",
    "ax.set_title('Range Profiles after MTI filter')\n",
    "\n",
    "#Set the y-axis ticks and labels\n",
    "yticks = np.linspace(0, 127, 10, dtype=int)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(['{:.2f}'.format(i*R_max/127) for i in yticks])\n",
    "\n",
    "xticks = np.linspace(0, mD_max, 30, dtype=int)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(['{:.0f}'.format(i*n_chirps/mD_max) for i in xticks])\n",
    "\n",
    "# Set the colorbar limits\n",
    "clim = im.get_clim()\n",
    "im.set_clim(clim[0] + 20 , clim[1])\n",
    "\n",
    "# Flip the y-axis to match MATLAB's behavior\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# # Adjust the y-axis limits\n",
    "# ax.set_ylim([0, 127])\n",
    "\n",
    "# Add the colorbar\n",
    "cbar = fig.colorbar(im, ax=ax)\n",
    "cbar.set_label('Magnitude (dB)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
